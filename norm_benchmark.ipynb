{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f9db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 114514\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.methods.DMF import DMFImputer\n",
    "from src.methods.DCAE import DCAEImputer\n",
    "\n",
    "pl.seed_everything(114514)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_path = Path(\"./data/Alzheimer.csv\")\n",
    "from src.datasets import CSVDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57084f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_copy(array):\n",
    "    return np.asarray(array, dtype=np.float64).copy()\n",
    "\n",
    "def z_score_normalize(data, eps=1e-8):\n",
    "    x = _safe_copy(data)\n",
    "    mean = np.nanmean(x, axis=0)\n",
    "    std = np.nanstd(x, axis=0)\n",
    "    std = np.where(std < eps, 1.0, std)\n",
    "    return (x - mean) / std, {\"mean\": mean, \"std\": std}\n",
    "\n",
    "def minmax_normalize(data, eps=1e-8):\n",
    "    x = _safe_copy(data)\n",
    "    feature_min = np.nanmin(x, axis=0)\n",
    "    feature_max = np.nanmax(x, axis=0)\n",
    "    span = feature_max - feature_min\n",
    "    span = np.where(span < eps, 1.0, span)\n",
    "    return (x - feature_min) / span, {\"min\": feature_min, \"max\": feature_max}\n",
    "\n",
    "def max_scale_normalize(data, eps=1e-8):\n",
    "    x = _safe_copy(data)\n",
    "    feature_max = np.nanmax(np.abs(x), axis=0)\n",
    "    feature_max = np.where(feature_max < eps, 1.0, feature_max)\n",
    "    return x / feature_max, {\"max_abs\": feature_max}\n",
    "\n",
    "def log2_transform(data, offset=1e-6):\n",
    "    x = _safe_copy(data)\n",
    "    min_val = np.nanmin(x, axis=0)\n",
    "    shift = np.where(min_val <= 0, np.abs(min_val) + offset, 0.0)\n",
    "    return np.log2(x + shift + offset), {\"shift\": shift, \"offset\": offset}\n",
    "\n",
    "def log2_z_score_normalize(data, eps=1e-8, offset=1e-6):\n",
    "    log_data, log_params = log2_transform(data, offset=offset)\n",
    "    norm_data, stats = z_score_normalize(log_data, eps=eps)\n",
    "    return norm_data, {\"log\": log_params, **stats}\n",
    "\n",
    "def log2_minmax_normalize(data, eps=1e-8, offset=1e-6):\n",
    "    log_data, log_params = log2_transform(data, offset=offset)\n",
    "    norm_data, stats = minmax_normalize(log_data, eps=eps)\n",
    "    return norm_data, {\"log\": log_params, **stats}\n",
    "\n",
    "def log2_max_scale_normalize(data, eps=1e-8, offset=1e-6):\n",
    "    log_data, log_params = log2_transform(data, offset=offset)\n",
    "    norm_data, stats = max_scale_normalize(log_data, eps=eps)\n",
    "    return norm_data, {\"log\": log_params, **stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ff02f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizers = {\n",
    "    \"z_score\": z_score_normalize,\n",
    "    \"minmax\": minmax_normalize,\n",
    "    \"max_scale\": max_scale_normalize,\n",
    "    \"log2_z_score\": log2_z_score_normalize,\n",
    "    \"log2_minmax\": log2_minmax_normalize,\n",
    "    \"log2_max_scale\": log2_max_scale_normalize,\n",
    "}\n",
    "imputers = [\"DMF\", \"DCAE\"]\n",
    "\n",
    "def load_data(data_path, missing_threshold=0.9):\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    df_original = pd.read_csv(data_path)\n",
    "    data_original = df_original.iloc[:, 1:].values.astype('float32')\n",
    "    original_missing_mask = (data_original <= 0) | np.isnan(data_original)\n",
    "\n",
    "    feature_missing_rate = original_missing_mask.mean(axis=0)\n",
    "    valid_features = feature_missing_rate < missing_threshold\n",
    "    data_filtered = data_original[:, valid_features]\n",
    "    missing_mask_filtered = original_missing_mask[:, valid_features]\n",
    "\n",
    "    feature_columns = df_original.columns[1:][valid_features] \n",
    "    df_filtered = pd.concat([df_original.iloc[:, [0]], \n",
    "                            pd.DataFrame(data_filtered, columns=feature_columns)], axis=1)\n",
    "\n",
    "    # 修复Path对象的处理\n",
    "    temp_path = str(data_path).replace('.csv', '_filtered.csv')\n",
    "    df_filtered.to_csv(temp_path, index=False)\n",
    "    dataset = CSVDataset(temp_path)\n",
    "    \n",
    "    print(f\"Filtered data shape: {data_filtered.shape}\")\n",
    "    print(f\"Filtered missing rate: {missing_mask_filtered.sum() / missing_mask_filtered.size:.2%}\")\n",
    "\n",
    "    return dataset, df_filtered, data_filtered, missing_mask_filtered\n",
    "\n",
    "\n",
    "def inverse_transform(method, imputed_norm, params):\n",
    "    if method == \"z_score\":\n",
    "        return imputed_norm * params[\"std\"] + params[\"mean\"]\n",
    "    if method == \"minmax\":\n",
    "        span = params[\"max\"] - params[\"min\"]\n",
    "        return imputed_norm * span + params[\"min\"]\n",
    "    if method == \"max_scale\":\n",
    "        return imputed_norm * params[\"max_abs\"]\n",
    "    log_params = params[\"log\"]\n",
    "    offset = log_params[\"offset\"]\n",
    "    shift = log_params[\"shift\"]\n",
    "    if method == \"log2_z_score\":\n",
    "        log_vals = imputed_norm * params[\"std\"] + params[\"mean\"]\n",
    "    elif method == \"log2_minmax\":\n",
    "        span = params[\"max\"] - params[\"min\"]\n",
    "        log_vals = imputed_norm * span + params[\"min\"]\n",
    "    elif method == \"log2_max_scale\":\n",
    "        log_vals = imputed_norm * params[\"max_abs\"]\n",
    "    else:\n",
    "        raise ValueError(method)\n",
    "    return np.power(2.0, log_vals) - shift - offset\n",
    "\n",
    "def train_imputer(name, data_tensor, mask_tensor, max_epochs=100):\n",
    "    if name == \"DMF\":\n",
    "        model = DMFImputer(\n",
    "            full_data_tensor=data_tensor,\n",
    "            full_mask_tensor=mask_tensor,\n",
    "            embedding_dim=64,\n",
    "            hidden_dims=[256, 128],\n",
    "            reconstruction_weight=1.0,\n",
    "            mask_weight=0.5,\n",
    "            lr=1e-3,\n",
    "            batch_size=512,\n",
    "        )\n",
    "    elif name == \"DCAE\":\n",
    "        model = DCAEImputer(\n",
    "            full_data_tensor=data_tensor,\n",
    "            full_mask_tensor=mask_tensor,\n",
    "            ae_dim=256,\n",
    "            mask_predictor_hidden_dim=128,\n",
    "            lambda_mask=0.5,\n",
    "            num_encoder_blocks=3,\n",
    "            num_decoder_blocks=3,\n",
    "            dilation=2,\n",
    "            learning_rate=1e-3,\n",
    "            batch_size=512,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(name)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=device,\n",
    "        devices=1,\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        logger=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        imputed = model.get_imputed_data().cpu().numpy()\n",
    "    return imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70717184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/Alzheimer.csv\n",
      "Filtered data shape: (210, 1494)\n",
      "Filtered missing rate: 18.88%\n",
      "Data shape: (210, 1494)\n",
      "Original missing: 59223\n",
      "Artificial mask: 130249\n",
      "Final train mask: 124268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizations:   0%|          | 0/6 [00:00<?, ?it/s]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing z_score...\n",
      "  NaN count after normalization: 59223\n",
      "  NaN in artificial positions: 0/130249\n",
      "  Training DMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 74972820935230.72\n",
      "  Training DCAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Normalizations:  17%|█▋        | 1/6 [02:49<14:05, 169.18s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 91543408796285.34\n",
      "\n",
      "Processing minmax...\n",
      "  NaN count after normalization: 59223\n",
      "  NaN in artificial positions: 0/130249\n",
      "  Training DMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 75771760781747.06\n",
      "  Training DCAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Normalizations:  33%|███▎      | 2/6 [05:39<11:19, 169.78s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 310036689074335.25\n",
      "\n",
      "Processing max_scale...\n",
      "  NaN count after normalization: 59223\n",
      "  NaN in artificial positions: 0/130249\n",
      "  Training DMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 77480950857146.70\n",
      "  Training DCAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Normalizations:  50%|█████     | 3/6 [08:29<08:29, 169.88s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 389767514446383.38\n",
      "\n",
      "Processing log2_z_score...\n",
      "  NaN count after normalization: 59223\n",
      "  NaN in artificial positions: 0/130249\n",
      "  Training DMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 74979229918399.41\n",
      "  Training DCAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Normalizations:  67%|██████▋   | 4/6 [11:16<05:37, 168.71s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 85145808381018.16\n",
      "\n",
      "Processing log2_minmax...\n",
      "  NaN count after normalization: 59223\n",
      "  NaN in artificial positions: 0/130249\n",
      "  Training DMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 83024379745690.70\n",
      "  Training DCAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Normalizations:  83%|████████▎ | 5/6 [14:03<02:48, 168.12s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 199091421129881.50\n",
      "\n",
      "Processing log2_max_scale...\n",
      "  NaN count after normalization: 59223\n",
      "  NaN in artificial positions: 0/130249\n",
      "  Training DMF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 347201747697170.50\n",
      "  Training DCAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Normalizations: 100%|██████████| 6/6 [16:51<00:00, 168.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ground truth NaN count: 0\n",
      "    Imputed NaN count: 0\n",
      "    Valid samples: 130249, MSE (original scale): 1072083346583429760.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalization</th>\n",
       "      <th>imputer</th>\n",
       "      <th>MSE</th>\n",
       "      <th>valid_count</th>\n",
       "      <th>artificial_masked_count</th>\n",
       "      <th>ground_truth_nan</th>\n",
       "      <th>imputed_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>log2_max_scale</td>\n",
       "      <td>DCAE</td>\n",
       "      <td>1.072083e+18</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>log2_max_scale</td>\n",
       "      <td>DMF</td>\n",
       "      <td>3.472017e+14</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>log2_minmax</td>\n",
       "      <td>DCAE</td>\n",
       "      <td>1.990914e+14</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>log2_minmax</td>\n",
       "      <td>DMF</td>\n",
       "      <td>8.302438e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>log2_z_score</td>\n",
       "      <td>DCAE</td>\n",
       "      <td>8.514581e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log2_z_score</td>\n",
       "      <td>DMF</td>\n",
       "      <td>7.497923e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max_scale</td>\n",
       "      <td>DCAE</td>\n",
       "      <td>3.897675e+14</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_scale</td>\n",
       "      <td>DMF</td>\n",
       "      <td>7.748095e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>minmax</td>\n",
       "      <td>DCAE</td>\n",
       "      <td>3.100367e+14</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minmax</td>\n",
       "      <td>DMF</td>\n",
       "      <td>7.577176e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z_score</td>\n",
       "      <td>DCAE</td>\n",
       "      <td>9.154341e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z_score</td>\n",
       "      <td>DMF</td>\n",
       "      <td>7.497282e+13</td>\n",
       "      <td>130249</td>\n",
       "      <td>130249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     normalization imputer           MSE  valid_count  \\\n",
       "11  log2_max_scale    DCAE  1.072083e+18       130249   \n",
       "10  log2_max_scale     DMF  3.472017e+14       130249   \n",
       "9      log2_minmax    DCAE  1.990914e+14       130249   \n",
       "8      log2_minmax     DMF  8.302438e+13       130249   \n",
       "7     log2_z_score    DCAE  8.514581e+13       130249   \n",
       "6     log2_z_score     DMF  7.497923e+13       130249   \n",
       "5        max_scale    DCAE  3.897675e+14       130249   \n",
       "4        max_scale     DMF  7.748095e+13       130249   \n",
       "3           minmax    DCAE  3.100367e+14       130249   \n",
       "2           minmax     DMF  7.577176e+13       130249   \n",
       "1          z_score    DCAE  9.154341e+13       130249   \n",
       "0          z_score     DMF  7.497282e+13       130249   \n",
       "\n",
       "    artificial_masked_count  ground_truth_nan  imputed_nan  \n",
       "11                   130249                 0            0  \n",
       "10                   130249                 0            0  \n",
       "9                    130249                 0            0  \n",
       "8                    130249                 0            0  \n",
       "7                    130249                 0            0  \n",
       "6                    130249                 0            0  \n",
       "5                    130249                 0            0  \n",
       "4                    130249                 0            0  \n",
       "3                    130249                 0            0  \n",
       "2                    130249                 0            0  \n",
       "1                    130249                 0            0  \n",
       "0                    130249                 0            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, df_filtered, data_filtered, original_missing = load_data(data_path, missing_threshold=0.9)\n",
    "\n",
    "raw_data = data_filtered.astype(np.float64)\n",
    "mask_from_dataset = dataset.get_mask().numpy().astype(bool)\n",
    "artificial_mask = ~mask_from_dataset  \n",
    "artificial_mask = artificial_mask & ~original_missing  \n",
    "final_train_mask = ~original_missing & ~artificial_mask\n",
    "\n",
    "print(f\"Data shape: {raw_data.shape}\")\n",
    "print(f\"Original missing: {original_missing.sum()}\")\n",
    "print(f\"Artificial mask: {artificial_mask.sum()}\")\n",
    "print(f\"Final train mask: {final_train_mask.sum()}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for norm_name, norm_fn in tqdm(normalizers.items(), desc=\"Normalizations\"):\n",
    "    print(f\"\\nProcessing {norm_name}...\")\n",
    "    \n",
    "    # 使用完整的原始数据计算归一化参数\n",
    "    raw_data_for_stats = raw_data.copy()\n",
    "    raw_data_for_stats[original_missing] = np.nan\n",
    "    \n",
    "    # 计算归一化参数\n",
    "    norm_data, params = norm_fn(raw_data_for_stats)\n",
    "    \n",
    "    # 创建训练用的数据：只有final_train_mask位置保留归一化值\n",
    "    norm_data_train = norm_data.copy()\n",
    "    norm_data_train[~final_train_mask] = np.nan\n",
    "    \n",
    "    # 检查归一化后的情况\n",
    "    nan_count = np.isnan(norm_data).sum()\n",
    "    print(f\"  NaN count after normalization: {nan_count}\")\n",
    "    \n",
    "    # 检查artificial_mask位置的ground truth\n",
    "    artificial_values_normalized = norm_data[artificial_mask]\n",
    "    nan_in_artificial = np.isnan(artificial_values_normalized).sum()\n",
    "    print(f\"  NaN in artificial positions: {nan_in_artificial}/{len(artificial_values_normalized)}\")\n",
    "    \n",
    "    if nan_in_artificial == len(artificial_values_normalized):\n",
    "        print(f\"  Skipping {norm_name}: all artificial positions are NaN\")\n",
    "        for imputer in imputers:\n",
    "            results.append({\n",
    "                \"normalization\": norm_name,\n",
    "                \"imputer\": imputer,\n",
    "                \"MSE\": float('inf'),\n",
    "                \"valid_count\": 0,\n",
    "                \"artificial_masked_count\": artificial_mask.sum(),\n",
    "                \"ground_truth_nan\": nan_in_artificial,\n",
    "                \"imputed_nan\": 0\n",
    "            })\n",
    "        continue\n",
    "    \n",
    "    # 准备训练数据\n",
    "    norm_data_filled = np.nan_to_num(norm_data_train, nan=0.0).astype(np.float32)\n",
    "    mask_tensor = torch.tensor(final_train_mask.astype(np.float32))\n",
    "    data_tensor = torch.tensor(norm_data_filled)\n",
    "    \n",
    "    for imputer in imputers:\n",
    "        print(f\"  Training {imputer}...\")\n",
    "        \n",
    "        imputed_norm = train_imputer(imputer, data_tensor, mask_tensor, max_epochs=500)\n",
    "\n",
    "        # 获取归一化尺度下的ground truth和imputed值\n",
    "        norm_ground_truth = norm_data[artificial_mask]\n",
    "        imputed_ground_truth = imputed_norm[artificial_mask]\n",
    "\n",
    "        print(f\"    Ground truth NaN count: {np.isnan(norm_ground_truth).sum()}\")\n",
    "        print(f\"    Imputed NaN count: {np.isnan(imputed_ground_truth).sum()}\")\n",
    "\n",
    "        valid_mask = ~(np.isnan(norm_ground_truth) | np.isnan(imputed_ground_truth))\n",
    "        \n",
    "        if valid_mask.sum() > 0:\n",
    "            # 转换回原始尺度进行MSE计算\n",
    "            original_ground_truth = raw_data[artificial_mask][valid_mask]\n",
    "            \n",
    "            # 将imputed值转换回原始尺度\n",
    "            imputed_full = imputed_norm.copy()\n",
    "            imputed_original = inverse_transform(norm_name, imputed_full, params)\n",
    "            imputed_original_values = imputed_original[artificial_mask][valid_mask]\n",
    "            \n",
    "            mse = mean_squared_error(original_ground_truth, imputed_original_values)\n",
    "            print(f\"    Valid samples: {valid_mask.sum()}, MSE (original scale): {mse:.2f}\")\n",
    "        else:\n",
    "            mse = float('inf')\n",
    "            print(f\"    No valid samples for comparison!\")\n",
    "        \n",
    "        results.append({\n",
    "            \"normalization\": norm_name,\n",
    "            \"imputer\": imputer,\n",
    "            \"MSE\": mse,\n",
    "            \"valid_count\": valid_mask.sum(),\n",
    "            \"artificial_masked_count\": artificial_mask.sum(),\n",
    "            \"ground_truth_nan\": np.isnan(norm_ground_truth).sum(),\n",
    "            \"imputed_nan\": np.isnan(imputed_ground_truth).sum()\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values([\"normalization\", \"imputer\"])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ba124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
